{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f097eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "(190594, 59)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "file_path = '/Users/junaeidshoaib/Desktop/Dessertation/Dataset/Matlab_49/BCICIV_1_mat/BCICIV_calib_ds1a.mat'\n",
    "data = sio.loadmat(file_path)\n",
    "\n",
    "# Convert to microvolts\n",
    "eeg_signals = 0.1 * data['cnt'].astype(np.float64)\n",
    "\n",
    "# Extract markers and sampling rate\n",
    "markers = data['mrk']\n",
    "positions = markers['pos'][0][0].flatten()  # Cue positions\n",
    "classes = markers['y'][0][0].flatten()  # Cue classes\n",
    "\n",
    "fs = data['nfo']['fs'][0][0][0][0]  # Sampling rate (e.g., 100 Hz)\n",
    "print(fs)\n",
    "print(eeg_signals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414d5e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials shape: (200, 400, 59)\n"
     ]
    }
   ],
   "source": [
    "# Define the time window for extracting trials (in seconds)\n",
    "fixation_time = 2\n",
    "cue_time = 4 #2-6 seconds cue \n",
    "trial_length = cue_time * fs  # Convert to samples\n",
    "\n",
    "# Extract trials\n",
    "trials = []\n",
    "trial_labels = []\n",
    "\n",
    "for pos, label in zip(positions, classes):\n",
    "    # Extract the segment from the EEG signals\n",
    "    trial = eeg_signals[pos:pos + int(trial_length), :]\n",
    "    trials.append(trial)\n",
    "    trial_labels.append(label)\n",
    "\n",
    "trials = np.array(trials)\n",
    "trial_labels = np.array(trial_labels)\n",
    "\n",
    "# Output the shape of the trials array\n",
    "print(\"Trials shape:\", trials.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e756186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (140, 400, 59)\n",
      "Testing set shape: (60, 400, 59)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Flatten trials to a 2D array (trials x features) if needed\n",
    "# We will keep them in 3D format for now: (num_trials, num_samples_per_trial, num_channels)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(trials, trial_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c05514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution: {-1: 100, 1: 100}\n",
      "Training Set Class Distribution: {-1: 70, 1: 70}\n",
      "Testing Set Class Distribution: {-1: 30, 1: 30}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate class distributions in the original dataset\n",
    "unique, counts = np.unique(trial_labels, return_counts=True)\n",
    "original_distribution = dict(zip(unique, counts))\n",
    "print(\"Original Class Distribution:\", original_distribution)\n",
    "\n",
    "# Calculate class distributions in the training set\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "train_distribution = dict(zip(unique, counts))\n",
    "print(\"Training Set Class Distribution:\", train_distribution)\n",
    "\n",
    "# Calculate class distributions in the testing set\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "test_distribution = dict(zip(unique, counts))\n",
    "print(\"Testing Set Class Distribution:\", test_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db3d17c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.3e+03 (2.2e-16 eps * 400 dim * 1.5e+16  max singular value)\n",
      "    Estimated rank (data): 400\n",
      "    data: rank 400 computed from 400 data channels with 0 projectors\n",
      "Reducing data rank from 400 -> 400\n",
      "Estimating class=-1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 3.3e+03 (2.2e-16 eps * 400 dim * 3.7e+16  max singular value)\n",
      "    Estimated rank (data): 400\n",
      "    data: rank 400 computed from 400 data channels with 0 projectors\n",
      "Reducing data rank from 400 -> 400\n",
      "Estimating class=-1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Training features shape: (140, 118)\n",
      "Testing features shape: (60, 118)\n"
     ]
    }
   ],
   "source": [
    "from mne.decoding import CSP\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# Define the bandpass filter function with proper normalization\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    nyq = 0.5 * fs  # Nyquist frequency\n",
    "    low = lowcut / nyq  # Normalize lowcut frequency\n",
    "    high = highcut / nyq  # Normalize highcut frequency\n",
    "    \n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    y = lfilter(b, a, data, axis=1)\n",
    "    return y\n",
    "\n",
    "# Define the frequency bands (Alpha and Beta)\n",
    "bands = [(8, 12), (12, 30)]  # Example: alpha and beta bands\n",
    "\n",
    "# Apply bandpass filters and CSP for each band\n",
    "X_train_features = []\n",
    "X_test_features = []\n",
    "\n",
    "for low, high in bands:\n",
    "    # Filter the data\n",
    "    X_train_filt = np.array([bandpass_filter(trial, low, high, fs) for trial in X_train])\n",
    "    X_test_filt = np.array([bandpass_filter(trial, low, high, fs) for trial in X_test])\n",
    "    \n",
    "    # Apply CSP\n",
    "    csp = CSP(n_components=59, reg=None, log=True, norm_trace=False)\n",
    "    X_train_csp = csp.fit_transform(X_train_filt, y_train)\n",
    "    X_test_csp = csp.transform(X_test_filt)\n",
    "    \n",
    "    # Append features\n",
    "    X_train_features.append(X_train_csp)\n",
    "    X_test_features.append(X_test_csp)\n",
    "\n",
    "# Concatenate features from all bands\n",
    "X_train_features = np.concatenate(X_train_features, axis=1)\n",
    "X_test_features = np.concatenate(X_test_features, axis=1)\n",
    "\n",
    "print(\"Training features shape:\", X_train_features.shape)\n",
    "print(\"Testing features shape:\", X_test_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "846a5131",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db9e101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a parameter grid to search over\n",
    "param_grid = {\n",
    "    'svc__C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'svc__kernel': ['linear', 'rbf'],  # Kernel type: linear or RBF (Radial Basis Function)\n",
    "    'svc__gamma': ['scale', 'auto']  # Kernel coefficient for RBF kernel\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c409158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best parameters found by grid search: {'svc__C': 0.1, 'svc__gamma': 'scale', 'svc__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with feature scaling and SVM\n",
    "svm_pipeline = make_pipeline(StandardScaler(), SVC())\n",
    "\n",
    "# Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(svm_pipeline, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the model using grid search\n",
    "grid_search.fit(X_train_features, y_train)\n",
    "\n",
    "# Get the best parameters and the corresponding model\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best parameters found by grid search:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06935819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy with best model: 0.5333333333333333\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.07      0.12        30\n",
      "           1       0.52      1.00      0.68        30\n",
      "\n",
      "    accuracy                           0.53        60\n",
      "   macro avg       0.76      0.53      0.40        60\n",
      "weighted avg       0.76      0.53      0.40        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set using the best model\n",
    "y_pred = best_model.predict(X_test_features)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy with best model:\", accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e405cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849afea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
