{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccd958b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape: (13337509, 59)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory containing the MATLAB files\n",
    "# directory = '/Users/junaeidshoaib/Desktop/Dessertation/Dataset/Matlab_49/BCICIV_1_mat'\n",
    "directory = '/Users/junaeidshoaib/Desktop/Dessertation/Dataset/Matlab/BCICIV_1calib_1000Hz_mat'\n",
    "\n",
    "# List all MATLAB files in the directory\n",
    "file_paths = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.mat')]\n",
    "\n",
    "# Initialize an empty list to hold dataframes\n",
    "dfs = []\n",
    "\n",
    "# Load each file and extract the EEG signals\n",
    "for file_path in file_paths:\n",
    "    data = sio.loadmat(file_path)\n",
    "    cnt = 0.1 * np.array(data['cnt'], dtype=np.float64)  # Convert to microvolts\n",
    "    df = pd.DataFrame(cnt)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "full_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(f'Combined DataFrame shape: {full_df.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d23a47b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     1     2     3     4     5     6     7     8     9   ...    49  \\\n",
      "0 -83.2 -35.7 -38.1 -58.0 -86.1 -27.1 -64.4 -60.8 -31.2 -36.0  ... -73.8   \n",
      "1 -77.0 -28.6 -34.5 -53.3 -80.9 -20.7 -58.3 -56.3 -27.0 -34.4  ... -69.4   \n",
      "2 -74.2 -23.5 -31.7 -50.9 -77.3 -16.5 -54.2 -52.6 -24.1 -34.3  ... -67.3   \n",
      "3 -75.3 -22.6 -33.5 -52.1 -78.4 -16.6 -54.7 -52.5 -25.4 -37.3  ... -69.9   \n",
      "4 -76.9 -24.3 -36.7 -54.4 -81.2 -18.8 -57.5 -55.2 -29.6 -39.3  ... -74.1   \n",
      "\n",
      "     50    51    52    53    54    55    56    57    58  \n",
      "0 -28.6 -64.7 -22.5 -23.0 -65.4 -83.6 -40.4 -41.3 -38.1  \n",
      "1 -24.4 -60.5 -19.1 -17.5 -60.1 -78.6 -35.6 -37.9 -32.7  \n",
      "2 -22.6 -57.5 -17.1 -15.1 -56.5 -77.0 -33.9 -36.4 -30.5  \n",
      "3 -24.4 -59.8 -18.5 -17.9 -58.8 -81.1 -37.8 -39.0 -34.3  \n",
      "4 -28.1 -64.3 -20.9 -21.8 -63.1 -84.8 -42.6 -43.2 -39.1  \n",
      "\n",
      "[5 rows x 59 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "print(full_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8930291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "# Function to create a Butterworth band-pass filter\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "# Function to apply the Butterworth filter to the data\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data, axis=0)\n",
    "    return y\n",
    "\n",
    "# Parameters for the bandpass filter\n",
    "lowcut = 8.0  # Alpha band lower edge\n",
    "highcut = 30.0  # Beta band upper edge\n",
    "fs = 1000  # Sampling rate (already downsampled to 100 Hz)\n",
    "\n",
    "# Apply the filter to the entire dataframe\n",
    "filtered_data = butter_bandpass_filter(full_df.values, lowcut, highcut, fs)\n",
    "\n",
    "# Convert the filtered data back to a DataFrame\n",
    "filtered_df = pd.DataFrame(filtered_data, columns=full_df.columns)\n",
    "\n",
    "# Display the shape and first few rows of the filtered DataFrame\n",
    "print(f'Filtered DataFrame shape: {filtered_df.shape}')\n",
    "print(filtered_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3baa860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the figure with a grid of subplots for each channel\n",
    "fig, axes = plt.subplots(4, 2, figsize=(16, 12), sharex=True)\n",
    "\n",
    "channels = [0, 1, 2, 3]  # Channels to plot\n",
    "labels = ['Channel 1', 'Channel 2', 'Channel 3', 'Channel 4']\n",
    "\n",
    "for i, ch in enumerate(channels):\n",
    "    # Plot original EEG signal\n",
    "    axes[i, 0].plot(full_df.iloc[:1300000, ch], label=labels[i], color='b')\n",
    "    axes[i, 0].set_title(f'Original EEG Signal - {labels[i]}')\n",
    "    axes[i, 0].set_ylabel('Amplitude (µV)')\n",
    "    axes[i, 0].grid(True)\n",
    "\n",
    "    # Plot filtered EEG signal\n",
    "    axes[i, 1].plot(filtered_df.iloc[:1300000, ch], label=labels[i], color='r')\n",
    "    axes[i, 1].set_title(f'Filtered EEG Signal - {labels[i]}')\n",
    "    axes[i, 1].set_ylabel('Amplitude (µV)')\n",
    "    axes[i, 1].grid(True)\n",
    "\n",
    "# Set common x-axis label\n",
    "for ax in axes[-1, :]:\n",
    "    ax.set_xlabel('Samples')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1917e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "mrk = data['mrk']\n",
    "\n",
    "# Extract the marker positions (in samples) and the corresponding class labels\n",
    "mrk_pos = np.array(mrk['pos'][0][0], dtype=np.int32).flatten()  # Positions of the cues\n",
    "mrk_y = np.array(mrk['y'][0][0], dtype=np.int32).flatten()  # Target classes (-1 for class one, 1 for class two)\n",
    "\n",
    "# Define the length of each trial (4 seconds = 400 samples at 100 Hz)\n",
    "trial_length = 400  # Only the task period\n",
    "\n",
    "# Initialize lists to store trials and labels\n",
    "trials = []\n",
    "labels = []\n",
    "\n",
    "# Loop over each marker position and extract the corresponding trial\n",
    "for pos, label in zip(mrk_pos, mrk_y):\n",
    "    # Ensure the trial doesn't exceed the data length\n",
    "    if pos + trial_length <= len(filtered_df):\n",
    "        # Extract the trial data starting from the marker position for 4 seconds\n",
    "        trial = filtered_df.iloc[pos:pos + trial_length].values\n",
    "        trials.append(trial)\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert to numpy arrays for easier manipulation\n",
    "trials = np.array(trials)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Display the shape of the segmented trials\n",
    "print(f'Number of trials: {trials.shape[0]}')\n",
    "print(f'Trial shape (samples x channels): {trials.shape[1:]}')\n",
    "\n",
    "# Optional: Visualize the first trial of the first channel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(trials[0][:, 0])\n",
    "plt.title(f'First Trial - Channel 1 - Label: {labels[0]}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f740961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling rate\n",
    "fs = 100  # Hz\n",
    "\n",
    "# Display start and end times for the first 5 trials\n",
    "for i in  range(min(5, len(mrk_pos))):\n",
    "    start_sample = mrk_pos[i]\n",
    "    end_sample = start_sample + trial_length\n",
    "    start_time = start_sample / fs\n",
    "    end_time = end_sample / fs\n",
    "    \n",
    "    print(f\"Trial {i+1}: Start time = {start_time:.2f}s, End time = {end_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6004e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first few marker positions\n",
    "print(\"First few marker positions (in samples):\", mrk_pos[:10])\n",
    "\n",
    "# Convert marker positions to time (in seconds)\n",
    "marker_times = mrk_pos / fs\n",
    "print(\"First few marker times (in seconds):\", marker_times[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of markers: {len(mrk_pos)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Perform stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(trials, labels, test_size=0.3, random_state=42, stratify=labels)\n",
    "\n",
    "# Check the new distribution\n",
    "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "train_distribution = dict(zip(unique_train, counts_train))\n",
    "print(f'Stratified Training set class distribution: {train_distribution}')\n",
    "\n",
    "unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "test_distribution = dict(zip(unique_test, counts_test))\n",
    "print(f'Stratified Test set class distribution: {test_distribution}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc785e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mne.decoding import CSP\n",
    "\n",
    "# Initialize CSP object with desired parameters\n",
    "csp = CSP(n_components=59, reg='ledoit_wolf', log=True, norm_trace=False)\n",
    "\n",
    "\n",
    "# Fit CSP on the training data\n",
    "X_train_csp = csp.fit_transform(X_train, y_train)\n",
    "\n",
    "# Apply CSP to the test data\n",
    "X_test_csp = csp.transform(X_test)\n",
    "\n",
    "# Output the shape of the CSP-transformed data\n",
    "print(f'CSP-transformed training set shape: {X_train_csp.shape}')\n",
    "print(f'CSP-transformed test set shape: {X_test_csp.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyswarm import pso\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random_seed = 71\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Define the objective function for PSO\n",
    "def svm_evaluate(features):\n",
    "    # Convert binary mask to feature selection\n",
    "    selected_features = X_train_csp[:, features > 0.5]\n",
    "    \n",
    "    # Ensure at least one feature is selected\n",
    "    if selected_features.shape[1] == 0:\n",
    "        return 1.0  # Assign a poor score if no features are selected\n",
    "    \n",
    "    # Train an SVM classifier on the selected features\n",
    "    clf = SVC(kernel='rbf', C=100, gamma='auto', random_state=random_seed)\n",
    "    \n",
    "    # Perform cross-validation to assess accuracy\n",
    "    scores = cross_val_score(clf, selected_features, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Return the negative mean accuracy (PSO minimizes, so we use negative to maximize accuracy)\n",
    "    return -scores.mean()\n",
    "\n",
    "# Define the bounds for PSO (0 to 1 for each feature)\n",
    "lb = [0] * X_train_csp.shape[1]  # Lower bounds\n",
    "ub = [1] * X_train_csp.shape[1]  # Upper bounds\n",
    "\n",
    "# Run PSO to select features\n",
    "best_features, _ = pso(svm_evaluate, lb, ub, swarmsize=50, maxiter=1000)\n",
    "\n",
    "# Convert the result to a binary mask\n",
    "best_features = best_features > 0.5\n",
    "selected_features_train = X_train_csp[:, best_features]\n",
    "selected_features_test = X_test_csp[:, best_features]\n",
    "\n",
    "# Train the final SVM model on the selected features\n",
    "final_clf = SVC(kernel='rbf', C=100, gamma='auto', random_state=random_seed)\n",
    "final_clf.fit(selected_features_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "test_accuracy = final_clf.score(selected_features_test, y_test)\n",
    "print(f'Test accuracy after PSO feature selection: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93834e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
