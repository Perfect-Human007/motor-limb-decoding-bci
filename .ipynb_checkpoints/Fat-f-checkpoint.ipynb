{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b671b1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for subject F: (190608, 59)\n",
      "Sampling rate for subject F: [[100]]\n",
      "Classes for subject F: [array([[array(['left'], dtype='<U4'), array(['foot'], dtype='<U4')]],\n",
      "       dtype=object)                                                  ]\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data_f = sio.loadmat('/Users/junaeidshoaib/Desktop/Dessertation/Dataset/Matlab_49/BCICIV_1_mat/BCICIV_calib_ds1f.mat')\n",
    "\n",
    "\n",
    "# Convert the EEG signals to microvolt values\n",
    "cnt_f = 0.1 * np.double(data_f['cnt'])\n",
    "\n",
    "\n",
    "# Check the shape of the loaded data for one subject\n",
    "print(f\"Data shape for subject F: {cnt_f.shape}\")\n",
    "print(f\"Sampling rate for subject F: {data_f['nfo']['fs'][0][0]}\")\n",
    "print(f\"Classes for subject F: {data_f['nfo']['classes'][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f960ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data shape for subject F: (190608, 59)\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    filtered_data = filtfilt(b, a, data, axis=0)\n",
    "    return filtered_data\n",
    "\n",
    "# Parameters for the bandpass filter\n",
    "lowcut = 8.0\n",
    "highcut = 15.0\n",
    "fs = 100  # Sampling rate\n",
    "\n",
    "# Apply the filter to subject F's data\n",
    "filtered_cnt_f = bandpass_filter(cnt_f, lowcut, highcut, fs)\n",
    "\n",
    "# Let's check the shape of the filtered data to ensure it matches the original\n",
    "print(f\"Filtered data shape for subject F: {filtered_cnt_f.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14df289a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_cnt_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m nperseg \u001b[38;5;241m=\u001b[39m fs \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Two-second windows\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Compute PSD using Welch's method\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m frequencies, psd \u001b[38;5;241m=\u001b[39m welch(filtered_cnt_c, fs, nperseg\u001b[38;5;241m=\u001b[39mnperseg, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Convert PSD to log scale (dB)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m log_psd \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog10(psd)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filtered_cnt_c' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "\n",
    "# Parameters\n",
    "nperseg = fs * 2  # Two-second windows\n",
    "\n",
    "# Compute PSD using Welch's method\n",
    "frequencies, psd = welch(filtered_cnt_c, fs, nperseg=nperseg, axis=0)\n",
    "\n",
    "# Convert PSD to log scale (dB)\n",
    "log_psd = 10 * np.log10(psd)\n",
    "\n",
    "# Plot the log power spectral density for each channel\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(log_psd.shape[1]):  # Iterate over each channel\n",
    "    plt.plot(frequencies, log_psd[:, i])\n",
    "\n",
    "plt.title('Log Power Spectral Density of Pre-Processed Data')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Log Power Spectral Density (10 * log10(Î¼V^2/Hz))')\n",
    "plt.xlim([0, 50])  \n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f3f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "# Perform ICA\n",
    "ica = FastICA(n_components=59, random_state=0)\n",
    "ica_data_f = ica.fit_transform(filtered_cnt_f)  # Reconstruct signals\n",
    "ica_data_f = ica_data_f @ ica.mixing_.T  # Reapply the mixing matrix\n",
    "\n",
    "# Check the shape of the ICA-processed data to confirm\n",
    "print(f\"ICA processed data shape for subject F: {ica_data_f.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb27f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the time window in terms of samples\n",
    "fs = 100  # Sampling rate (100 Hz)\n",
    "start_sample = int(0.5 * fs)  # Start 0.5 seconds after the marker (50 samples)\n",
    "end_sample = int(2.5 * fs)    # End 2.5 seconds after the marker (250 samples)\n",
    "epoch_length = end_sample - start_sample  # Length of the time window (200 samples)\n",
    "\n",
    "# Extract marker positions correctly\n",
    "marker_positions = data_f['mrk']['pos'][0][0].flatten()  # Flatten to get a 1D array of marker positions\n",
    "\n",
    "# Print out the first few marker positions to ensure correctness\n",
    "print(f\"First 10 marker positions: {marker_positions[:10]}\")\n",
    "\n",
    "# Determine the number of trials\n",
    "n_trials = len(marker_positions)\n",
    "\n",
    "# Preallocate the trials array to hold the segmented data\n",
    "trials = np.zeros((n_trials, 59, epoch_length))  # 59 channels, 200 samples per trial\n",
    "\n",
    "# Extract the trials based on the time window relative to each marker position\n",
    "for i in range(n_trials):\n",
    "    start_pos = int(marker_positions[i])  # Extract the scalar value from the flattened array\n",
    "    start_idx = start_pos + start_sample  # Start index for extraction (0.5s after marker)\n",
    "    end_idx = start_pos + end_sample      # End index for extraction (2.5s after marker)\n",
    "    \n",
    "    # Extract and store the trial data\n",
    "    trials[i] = ica_data_f[start_idx:end_idx, :].T  # Transpose to match (channels, samples)\n",
    "\n",
    "# Verify the shape of the trials\n",
    "print(f\"Trials shape after time window segmentation: {trials.shape}\")\n",
    "\n",
    "# Print out a few details of the extracted trials\n",
    "print(f\"First trial (shape): {trials[1].shape}\")\n",
    "print(f\"First trial (data snippet): {trials[0][:, :5]}\")  # Show a snippet of the first 5 samples\n",
    "\n",
    "\n",
    "# Extract the labels for each trial\n",
    "labels = data_f['mrk']['y'][0][0].flatten()  # Flatten the array to ensure it's 1D\n",
    "\n",
    "# Verify the shape and content of the labels\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"First 10 labels: {labels[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6f0b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mne.decoding import CSP\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the CSP object with the number of components\n",
    "csp = CSP(n_components=6, reg=None, log=True, cov_est='epoch')\n",
    "\n",
    "# Fit the CSP to the segmented trials and labels\n",
    "csp.fit(trials, labels)\n",
    "\n",
    "# Transform the trials using the fitted CSP model\n",
    "csp_features = csp.transform(trials)\n",
    "\n",
    "# Verify the shape of the extracted features\n",
    "print(f\"CSP Features shape: {csp_features.shape}\")\n",
    "\n",
    "# Split the CSP features into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(csp_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a classifier \n",
    "classifier = SVC(kernel='linear')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Plot the distribution of the first two CSP components\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(csp_features[:, 0], csp_features[:, 1], c=labels, cmap='coolwarm')\n",
    "plt.title('Distribution of the first two CSP components')\n",
    "plt.xlabel('CSP Component 1')\n",
    "plt.ylabel('CSP Component 2')\n",
    "plt.colorbar(label='Class Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360a3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Initialize LDA classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Train the LDA classifier\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_lda = lda.predict(X_test)\n",
    "accuracy_lda = accuracy_score(y_test, y_pred_lda)\n",
    "print(f\"LDA Classification Accuracy: {accuracy_lda * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize SVM classifier with Gaussian kernel and specified parameters\n",
    "svm = SVC(kernel='rbf', C=0.057704, gamma='scale')\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Classification Accuracy: {accuracy_svm * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3237bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize Logistic Regression classifier\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the Logistic Regression classifier\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "print(f\"Logistic Regression Classification Accuracy: {accuracy_log_reg * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5061daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize Decision Tree classifier with specified parameters\n",
    "complex_tree = DecisionTreeClassifier(max_depth=15, criterion='entropy')\n",
    "\n",
    "# Train the Decision Tree classifier\n",
    "complex_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_tree = complex_tree.predict(X_test)\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "print(f\"Complex Tree Classification Accuracy: {accuracy_tree * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ac7b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize Gaussian Naive Bayes classifier\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_nb = naive_bayes.predict(X_test)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"Naive Bayes Classification Accuracy: {accuracy_nb * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d994644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize KNN classifier with specified parameters\n",
    "knn = KNeighborsClassifier(n_neighbors=100, metric='mahalanobis', metric_params={'VI': np.cov(X_train, rowvar=False)}, weights='distance')\n",
    "\n",
    "# Train the KNN classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"KNN Classification Accuracy: {accuracy_knn * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36335b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
